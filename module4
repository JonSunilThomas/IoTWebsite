Module 4: Analytics & AI Integration
Overall Function:

This module is the intelligence and memory of the platform. Its purpose is to transform raw historical data into meaningful insights and actionable information. It provides the services to query past data, to communicate with external AI models for advanced analysis, and to generate and deliver alerts to the user.
Sub-Module 4.1: Historical Data Service
Function:

This sub-module acts as the archive librarian. It provides the necessary API endpoints for the frontend to retrieve historical telemetry data from the database for analysis, comparison, and visualization.
What Has to Be Done:

    4.1.1: Telemetry Query Endpoint:

        Create an Express route handler for GET /api/telemetry/:deviceId.

        This endpoint will be protected by JWT middleware and will validate that the user owns the requested device.

        It will accept query parameters for time ranges (e.g., ?start=...&end=... or ?range=24h).

        The controller will perform a query on the MongoDB telemetry collection, filtering by deviceId and the specified timestamp range.

        Performance: A compound index must be created in MongoDB on { deviceId: 1, timestamp: -1 } to ensure these queries are extremely fast, even with millions of records.

    4.1.2: Data Aggregation API:

        Create endpoints for server-side data aggregation, for example, GET /api/telemetry/:deviceId/summary.

        This is for generating summary statistics without sending all the raw data to the frontend.

        Use MongoDB's Aggregation Pipeline to calculate metrics like average, min, max, and count over a given period. This significantly reduces the amount of data transferred to the client.

Checklist:

    [ ] Create a compound index on the telemetry collection in MongoDB.

    [ ] Create telemetry.routes.js and telemetry.controller.js.

    [ ] Implement the GET /api/telemetry/:deviceId endpoint with time range query parameters.

    [ ] Implement the GET /api/telemetry/:deviceId/summary endpoint using the MongoDB Aggregation Pipeline.

    [ ] Ensure all endpoints are protected and properly scoped to the device owner.

Sub-Module 4.2: AI Service Interface
Function:

This sub-module is the external consultant. It manages all communication with the deployed machine learning models, sending them data for analysis and processing their responses.
What Has to Be Done:

    4.2.1: AI Model Connector:

        Create a dedicated service file (e.g., ai.service.js).

        This service will use an HTTP client library like axios to make POST requests to the secure API endpoints of your deployed AI models (e.g., on Amazon SageMaker, Google AI Platform, or another service).

        It will handle formatting the data correctly for the AI model and parsing the model's JSON response.

    4.2.2: Real-time Anomaly Detection:

        This service will listen for the global new-data event emitted by Module 2.

        For each new data point, it will asynchronously call the AI Model Connector to send the data to the Anomaly Detection model.

        If the model's response indicates an anomaly, this service will emit a new internal event: eventEmitter.emit('anomaly-detected', { deviceId, anomalyDetails, timestamp }).

    4.2.3: On-Demand Analysis:

        Create an Express route handler for POST /api/analysis/:deviceId.

        This endpoint will be called when a user clicks an "Analyze" button on the frontend.

        The controller will first fetch a recent block of historical data for the device (using Sub-Module 4.1).

        It will then send this block of data to the AI Service Interface to get a more in-depth analysis (e.g., a predictive maintenance forecast). The result is then sent back to the user.

Checklist:

    [ ] Install axios (npm install axios).

    [ ] Create the ai.service.js file to manage all external API calls to AI models.

    [ ] Create a listener for the new-data global event.

    [ ] Implement the logic to call the anomaly detection model and emit an anomaly-detected event on a positive result.

    [ ] Implement the POST /api/analysis/:deviceId endpoint for on-demand analysis.

Sub-Module 4.3: Notification & Alerting Service
Function:

This sub-module is the central dispatch for alerts. It listens for internal events generated by the AI service and is responsible for formatting them into user-friendly notifications and delivering them to the correct user in real-time.
What Has to Be Done:

    4.3.1: Alert Listener:

        This service will listen for the anomaly-detected event (and other future alert events) from the global event emitter.

    4.3.2: Notification Broadcaster:

        When an alert event is received, the service will:

            Look up the device in MongoDB to find its owner's userId.

            Format the raw alert data into a human-readable message (e.g., "Anomaly detected on 'Motor 1': Voltage is 20% higher than normal.").

            Use the socket.io instance (from Module 2) to push this formatted notification to the specific user's private room (io.to(userId).emit('new-alert', notificationObject)).

Checklist:

    [ ] Create a listener for the anomaly-detected global event.

    [ ] Implement the logic to look up the device owner's userId.

    [ ] Implement the logic to format the alert into a user-friendly notification object.

    [ ] Integrate with the socket.io service to broadcast the notification to the correct user.
